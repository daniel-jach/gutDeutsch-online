[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "",
    "text": "In diesem Kurs lernen oder üben Sie …\n\ndeutsche und chinesische und arabische Volksmärchen in deutscher Übersetzung zu lesen.\nin Märchen tradierte kulturspezifische Bilderwelten und Narrative zu erkennen und wiederzugeben.\n…\nsprachliche Daten in computerlesbare Daten umzuwandeln.\nDaten quantitativ zu analysieren und sachbezogen zu interpretieren."
  },
  {
    "objectID": "index.html#r",
    "href": "index.html#r",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "R",
    "text": "R\nR Freie Programmiersprache für statistische Berechnungen und Grafiken\n Anwendungen von R außerhalb der Wissenschaft1"
  },
  {
    "objectID": "index.html#text-mining",
    "href": "index.html#text-mining",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "Text Mining",
    "text": "Text Mining\nText Mining Vorgang, bei dem ungeordnete sprachliche Daten (Texte) mit dem Computer geordnet und dann nach bedeutungsvollen Mustern durchsucht werden (https://www.ibm.com/cloud/learn/text-mining)\nSuche nach Text Mining auf dem Jobportal Indeed.com am 07.09.2021 ergibt Gesuche von:"
  },
  {
    "objectID": "index.html#datengrundlage-text",
    "href": "index.html#datengrundlage-text",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "Datengrundlage Text",
    "text": "Datengrundlage Text\nKorpus Große, digitale Sammlung von Texten\nKorpus-Linguistik Teil der Sprachwissenschaft, der Korpora und bestimmte Untersuchungsmethoden nutzt\n\n\n\nKorpus\nWörter\n\n\n\n\nDeReKo\n46,9 Mrd.\n\n\niWeb\n14 Bio.\n\n\nDiSKo\n180 k\n\n\n\n\n\n\nUnsere Korpora\nWörter\nTexte\n\n\n\n\nGrimm Märchenkorpus2\n259 k\n211\n\n\nChinesische Volksmärchen3\n108 k\n100\n\n\nArabische Volksmärchen4\n782 k\n169"
  },
  {
    "objectID": "index.html#erste-aufgaben",
    "href": "index.html#erste-aufgaben",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "Erste Aufgaben",
    "text": "Erste Aufgaben\n\nWählen Sie ein deutsches, ein chinesisches und ein arabisches Volksmärchen aus.\n\n\n\n\n\nChina “Intranet”\n\n\n\n\nDeutsche Märchen\nshorturl.at/rwIK8\n\n\nChinesische Märchen\nshorturl.at/jnzBW\n\n\nArabische Märchen\nshorturl.at/dqxCP\n\n\n\n\nLesen Sie Ihre Märchen.\nSuchen Sie im Internet ein passendes Bild für jedes Ihrer Märchen.\nSchicken Sie mir Bilder und Titel Ihrer Märchen."
  },
  {
    "objectID": "index.html#erste-aufgaben-1",
    "href": "index.html#erste-aufgaben-1",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "Erste Aufgaben",
    "text": "Erste Aufgaben\nVersuchen Sie, R und RStudio auf Ihrem Computer zu installieren.\nWindows/Mac\n\nR\n\nBesuchen Sie CRAN (Comprehensive R Archive Network) https://cran.r-project.org/.\nLaden Sie die für Sie richtige Version von R (Windows, Mac) herunter.\nInstallieren Sie R auf Ihrem Computer.\n\nR Studio\n\nBesuchen Sie https://rstudio.com/products/rstudio/download/#download.\nLaden Sie die richtige Version für Ihren Computer herunter.\nInstallieren Sie R Studio auf Ihrem Computer.\n\n\nUbuntu\n\nsudo apt-get install r-base\nsudo apt-get install gdebi-core\nwget https://download2.rstudio.org/server/debian9/x86_64/\n  rstudio-server-1.4.1103-amd64.deb\nsudo gdebi rstudio-server-1.4.1103-amd64.deb"
  },
  {
    "objectID": "about.html#beschreibung",
    "href": "about.html#beschreibung",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "Beschreibung",
    "text": "Beschreibung\nEs war einmal vor langer Zeit, da war die Linguistik eine historisch-vergleichende Geisteswissenschaft, suchte gewissenhaft nach der Herkunft einer Sprache und schrieb dicke Bücher über ihre Regeln. Das war einmal. Die moderne Linguistik ist vielseitig und Teil einer Familie von Wissenschaften, die ihre Forschungsfragen mit Hilfe von Daten und Computern beantworten. Dabei nutzt sie Methoden, die nicht auf akademische Forschung beschränkt sind, sondern die auch in Industrie und Handel zum Einsatz kommen.\nIn diesem Kurs lernen Sie neue Methoden der Datenanalyse an einem alten Beispiel kennen: Märchen. Märchen sind gute Beispiele für Erzähltexte (narrative Texte), ihre Analyse bringt Einsicht in das Weltbild und die Bilderwelt einer Sprachgemeinschaft. Sie sind außerdem auch für Deutsch-als-Fremdsprache-Studierende ab A2/B1-Niveau schon verständlich. Im Kurs lesen wir deutschsprachige Märchen der Brüder Grimm und chinesische und arabische Volksmärchen in deutscher Übersetzung. Wir analysieren anschließend verschiedene Aspekte zuerst von Hand und dann mit dem Computer. Die Ergebnisse der Analysen werden von den Teilnehmenden interpretiert und vorgestellt.\nDie Unterrichtssprache ist Deutsch. Sie benötigen einen Laptop und Internet.\nIhre Note besteht aus Ihrer Anwesenheit (20%), der Entwicklung und dem Vortrag eines eigenen kleinen Projekts (40%) und einer Take-Home-Prüfung (40%)."
  },
  {
    "objectID": "about.html#lernziele",
    "href": "about.html#lernziele",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "Lernziele",
    "text": "Lernziele\nIn diesem Kurs lernen oder üben Sie …\n\ndeutsche und chinesische und arabische Volksmärchen in deutscher Übersetzung zu lesen.\nin Märchen tradierte kulturspezifische Bilderwelten und Narrative zu erkennen und wiederzugeben.\n…\nsprachliche Daten in computerlesbare Daten umzuwandeln.\nDaten quantitativ zu analysieren und sachbezogen zu interpretieren."
  },
  {
    "objectID": "about.html#plan",
    "href": "about.html#plan",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "Plan",
    "text": "Plan\n\n\n\n\n\n\n\nEinheit\nThema\n\n\n\n\n1\nEinführung: Was Korpus, R und Text Mining sind und was das Ganze eigentlich soll\n\n\n2\nDas Korpus kennenlernen: Gemeinsam Märchen lesen und verstehen\n\n\n3\nDas Korpus kennenlernen: Gemeinsam Märchen lesen und verstehen\n\n\n4\nR: Erste Schritte mit R\n\n\n5\nEins, zwei, drei, vier, fünf…: Tokenisierung und Wort-Häufigkeiten\n\n\n6\nEins, zwei, drei, vier, fünf…: Tokenisierung und Wort-Häufigkeiten\n\n\n7\nGut und Böse, Liebe und Hass: Stimmungsanalyse (sentiment analysis)\n\n\n8\nGut und Böse, Liebe und Hass: Stimmungsanalyse (sentiment analysis)\n\n\n9\nDas ist doch eh alles dasselbe, oder?: Ähnlichkeitsanalyse (cosine similarity)\n\n\n10\nDas ist doch eh alles dasselbe, oder?: Ähnlichkeitsanalyse (cosine similarity)\n\n\n11\nWeiber, Wölfe, Wälder: Themenanalyse (topic modeling)\n\n\n12\nWeiber, Wölfe, Wälder: Themenanalyse (topic modeling)\n\n\n13\nMärchen qualitativ analysieren…\n\n\n14\nMärchen qualitativ analysieren…\n\n\n15\n…und quantitativ auswerten.\n\n\n16\n…und quantitativ auswerten.\n\n\n17\nTake-Home-Prüfung\n\n\n\n(90 Minuten / Einheit)"
  },
  {
    "objectID": "intro-to-R.html",
    "href": "intro-to-R.html",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "",
    "text": "R ist eine freie Programmiersprache für statistische Berechnungen und das Erstellen von Grafiken. Die folgende Einführung basiert auf Levshina (2015)."
  },
  {
    "objectID": "intro-to-R.html#hausaufgabe",
    "href": "intro-to-R.html#hausaufgabe",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "Hausaufgabe",
    "text": "Hausaufgabe\n\nErstellen Sie einen Vektor mit dem Alter aller Kursteilnehmerinnen in Jahren.\nBerechnen Sie den Altersdurchschnitt.\nWählen Sie zufällig zehn Wörter aus Ihrem Wörterbuch aus. Erstellen Sie einen data frame mit vier Spalten: Token, Wortart, Anzahl der Bedeutungen und ob das Wort einen Umlaut (ä, ü, ö) enthält.\nErstellen Sie eine Häufigkeitstabelle für die Wortarten aus Ihrem data frame.\nErstellen Sie eine Grafik für Ihre Häufigkeiten.\nInstallieren Sie folgende Pakete.\n\n\ninstall.packages(c(\"dplyr\", \"tm\", \"tidytext\", \"tools\", \"ggplot2\"), dependencies = TRUE)"
  },
  {
    "objectID": "tokenization-and-frequency.html",
    "href": "tokenization-and-frequency.html",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "",
    "text": "Im Folgenden werden Sie (1) Ihr Märchen in R laden, (2) Wort-Tokens und Wort-Types zählen, (3) die Ergebnisse in einer Grafik visualisieren und vergleichen. Diese Abschnitte basieren auf (Silge.2017?). Anschließend (4) vergleichen Sie drei große Korpora deutscher, chinesischer und arabischer Volksmärchen.\n\nPakete installieren\nBevor Sie beginnen, müssen Sie einige Pakete (packages) mit install.packages(\"PAKETNAME\") installieren. Die Pakete enthalten verschiedene nötige Funktionen. Anschließend müssen Sie die installierten Pakete mit library(PAKETNAME) aktivieren. Einmal aktiviert, bleibt das Paket aktiv. Das werden Sie später tun.\n\ninstall.packages(c(\"tidytext\", \"dplyr\", \"tm\", \"tools\", \"ggplot2\", \"gridExtra\"), dependencies = TRUE)\n\n\n\nMärchen laden\nLesen Sie zuerst Ihr Märchen in R ein. Hierfür nutzen Sie readLines().\n\nfileConn<-file(\"./data/sample/das_liebespaar_in_der_schule.txt\")\ntext<-readLines(fileConn)\nclose(fileConn)\ntext\n\nDas Objekt text enthält Ihren Text. Welche Art von Objekt ist text?\nAls Nächstes wandeln Sie das Objekt text in einen data frame um. Diesmal benutzen Sie dafür die Funktion tibble(). Ein tibble ist eine besonders praktische Art von data frame. Aktivieren Sie das Paket dplyr. Dann benutzen Sie die Funktion tibble().\n\nlibrary(dplyr)\n\ntext_df<-tibble(TEXT = text)\ntext_df\n\nstr(text_df)\n\n\nKleine Aufgabe\nWie ist Ihr Text jetzt gespeichert? Zeigen Sie die interne Struktur Ihres tibble an.\n\n\n\nTokens und Types zählen\nUm die Wörter in Ihrem Text zu zählen, müssen Sie den Text in einzelne Wörter aufteilen (tokenisieren). Das macht die Funktion unnest_tokens(). Sie können alles in eine Zeile schreiben oder einen Pipe-Operator %>% benutzen. f(x) ist identisch mit x %>% f. Ein Pipe-Operator macht komplexe Befehl besser lesbar.\n\nlibrary(tidytext)\n\n# Befehl ohne Pipe\nprint(\"Hello Chengdu!\")\n\n# Befehl mit Pipe\n\"Hello Chengdu!\" %>%\n  print()\n\n# Befehl ohne Pipe\ntokens_df<-unnest_tokens(text_df, WORD, TEXT, to_lower = FALSE)\n\n# Befehl mit Pipe\ntokens_df<-text_df %>%\n  unnest_tokens(WORD, TEXT, to_lower = FALSE)\ntokens_df\n\n\nKleine Aufgabe\nWie ist Ihr Text jetzt gespeichert? Zeigen Sie den tibble an. Wieviele Wörter (Tokens) enthält Ihr Text insgesamt?\n\nIhr Text enthält noch sogenannte Stopwörter. Solche Wörter werden normalerweise vor der Analyse entfernt. Das tm-Paket enthält Listen von Stopwörtern in verschiedenen Sprachen, die Sie mit der Funktion stopwords() aufrufen. Ich habe einen data frame für Sie vorbereitet (ohne ä, ü, ö usw.).\n\nlibrary(tm)\n\nstopwords<-stopwords(\"de\")\nstopwords\n\nstopwords_df<-read.table(\"./data/stopwords.csv\", header = TRUE)\nstopwords_df\n\n\nDenkpause\nWas sind Stoppwörter für Wörter? Wieso werden sie normalerweise vor der Analyse entfernt?\n\nUm die Stopwörter aus Ihrem Text zu entfernen, führen Sie folgenden Befehl aus.\n\ntokens_df<-tokens_df %>%\n  anti_join(stopwords_df, by = \"WORD\")\ntokens_df\n\nDie Funktion count() zählt Wörter. Führen Sie hierzu folgenden Befehl aus.\n\nfreq_df<-tokens_df %>%\n  count(WORD, sort = TRUE)\nfreq_df\n\n\nKleine Aufgabe\nZeigen Sie das Ergebnis in Form eines tibble an. Wieviele verschiedene Wörter (Types) sind in Ihrem Text enthalten? Wie häufig ist das häufigste Wort (Type)?\n\n\n\nErgebnisse veranschaulichen\nVisualisieren Sie die Häufigkeitsverteilung für die 30 häufigsten Wörter in Ihrem Text als Balkengrafik.\n\nlibrary(ggplot2)\n\nfreq_df[1:30,] %>%\n  mutate(WORD=factor(WORD, levels = rev(WORD))) %>%\n  ggplot(aes(x = n, y = WORD)) + \n  geom_col(fill = \"steelblue\") + \n  labs(y = NULL, x = \"Anzahl\") + \n  ggtitle(\"Worthäufigkeit im Text\") +\n  theme_light()\n\n\nKleine Aufgabe\nVergleichen Sie Ihre Grafik mit denen Ihrer Mitstudierenden. Welche Unterschiede, welche Gemeinsamkeiten finden Sie?\n\n\n\nKorpora vergleichen\nEinzelne Märchentexte zu analysieren macht Spaß und ist lehrreich, aber Text Mining nutzt normalerweise viele Texte und große Mengen von Daten. So werden Muster sichtbar, die an ein paar einzelnen Texten nicht erkennbar sind.\nDas Grimm-Korpus besteht aus 211 Märchen der Brüder Grimm. Das Wilhelm-Korpus besteht aus 100 chinesischen Volksmärchen, das Weil-Korpus aus 169 arabischen Märchen, die ins Deutsche übertragen sind.\n\nAufgabe\nBilden Sie Gruppen und erarbeiten Sie die Häufigkeitsverteilung für eines der Korpora. Vergleichen Sie dann Ihre Ergebnisse mit den Ergebnissen der anderen Gruppen. Welche Gemeinsamkeiten, welche Unterschiede finden Sie? Wie interpretieren Sie die Ergebnisse? Diskutieren Sie und stellen Sie dann das Ergebnis Ihrer Diskussion im Plenum vor.\n\nAls Erstes lesen Sie die zwei Korpora ein. Sie können den Code kopieren und ausführen.\n\nsrc<-list.files(\"./data/corpus-wilhelm/\")\ndf<-data.frame(matrix(nrow = length(src), ncol = 2))\ncolnames(df)<-c(\"TEXT\", \"DATEI\")\nfor(i in 1:length(src)){\n  df[i,1]<-readLines(paste(\"./data/corpus-wilhelm/\", src[i], sep = \"\"))\n  df[i,2]<-src[i]\n}\nwilhelm<-as_tibble(df)\n\nsrc<-list.files(\"./data/corpus-grimm/\")\ndf<-data.frame(matrix(nrow = length(src), ncol = 2))\ncolnames(df)<-c(\"TEXT\", \"DATEI\")\nfor(i in 1:length(src)){\n  df[i,1]<-readLines(paste(\"./data/corpus-grimm/\", src[i], sep = \"\"))\n  df[i,2]<-src[i]\n}\ngrimm<-as_tibble(df)\n\nsrc<-list.files(\"./data/corpus-weil/\")\ndf<-data.frame(matrix(nrow = length(src), ncol = 2))\ncolnames(df)<-c(\"TEXT\", \"DATEI\")\nfor(i in 1:length(src)){\n  df[i,1]<-readLines(paste(\"./data/corpus-weil/\", src[i], sep = \"\"))\n  df[i,2]<-src[i]\n}\nweil<-as_tibble(df)\n\nrm(df, i, src)\n\nwilhelm\n\nJetzt machen Sie ohne mich weiter. Versuchen Sie, die Schritte (2) und (3) selbstständig mit den Korpusdaten zu wiederholen. Wenn Sie Probleme haben, klicken Sie auf Hilfe.\n\n\nHilfe\n\n\nwilhelm_tok<-wilhelm %>%\n  unnest_tokens(WORD, TEXT, to_lower = FALSE)\ngrimm_tok<-grimm %>%\n  unnest_tokens(WORD, TEXT, to_lower = FALSE)\nweil_tok<-weil %>%\n  unnest_tokens(WORD, TEXT, to_lower = FALSE)\n\nstopwords_df<-read.table(\"./data/stopwords.csv\", header = TRUE)\n\ngrimm_tok<-anti_join(grimm_tok, stopwords_df)\nwilhelm_tok<-anti_join(wilhelm_tok, stopwords_df)\nweil_tok<-anti_join(weil_tok, stopwords_df)\n\n\n\ngrimm_freq<-grimm_tok %>%\n  count(WORD, sort = TRUE)\nwilhelm_freq<-wilhelm_tok %>%\n  count(WORD, sort = TRUE)\nweil_freq<-weil_tok %>%\n  count(WORD, sort = TRUE)\n\ngrimm_plot<-grimm_freq[1:20,] %>%\n  mutate(WORD=factor(WORD, levels = rev(WORD))) %>%\n  ggplot(aes(x = n, y = WORD)) + \n  geom_col(fill = \"steelblue\") + \n  labs(y = NULL, x = \"Anzahl\") + \n  theme_light() +\n  ggtitle(\"Deutsch\")\n\nwilhelm_plot<-wilhelm_freq[1:20,] %>%\n  mutate(WORD=factor(WORD, levels = rev(WORD))) %>%\n  ggplot(aes(x = n, y = WORD)) + \n  geom_col(fill = \"steelblue\") + \n  labs(y = NULL, x = \"Anzahl\") + \n  theme_light() +\n  ggtitle(\"Chinesisch\")\n\nweil_plot<-weil_freq[1:20,] %>%\n  mutate(WORD=factor(WORD, levels = rev(WORD))) %>%\n  ggplot(aes(x = n, y = WORD)) + \n  geom_col(fill = \"steelblue\") + \n  labs(y = NULL, x = \"Anzahl\") + \n  theme_light() +\n  ggtitle(\"Arabisch\") +\n  theme(axis.text.x = element_text(angle = 20, vjust = 0.5, hjust=1))\n\nlibrary(gridExtra)\ngrid.arrange(grimm_plot, wilhelm_plot, weil_plot, nrow = 1)"
  },
  {
    "objectID": "sentiment-analysis.html",
    "href": "sentiment-analysis.html",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "",
    "text": "Das englische Wort sentiment bedeutet auf Deutsch Stimmung oder Meinung, auf Chinesisch 情绪 oder 意见. Die sentiment analysis ist ein Teil von Text Mining und bezeichnet die automatische Auswertung von Texten mit dem Ziel, eine [Äußerung] als positiv oder negativ zu erkennen (Wikipedia, 16.01.2021). Das ist sprachwissenschaftlich relevant, aber zum Beispiel auch für Händler oder in der Werbung wichtig.\nIm Folgenden werden Sie (1) die Stimmung Ihres Märchens analysieren und visualisieren und die Ergebnisse vergleichen. (2) Die Stimmung deutscher, chinesischer und arabischer Märchen analysieren und vergleichen.\n\nPakete installieren\nBevor Sie beginnen, müssen Sie einige Pakete installieren und die nötigen Pakete aktivieren.\n\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(tm)\nlibrary(tools)\nlibrary(wordcloud)\nlibrary(reshape2)\nlibrary(ggplot2)\n\n\n\nStimmung analysieren\nLesen Sie Ihren Märchentext ein. Zur Erinnerung:\n\nfileConn<-file(\"./data/sample/das_liebespaar_in_der_schule.txt\")\ntext<-readLines(fileConn)\nclose(fileConn)\ntext\n\ntext_df<-tibble(TEXT = text)\n\nFür eine Stimmungsanalyse Ihres Märchens benötigen Sie ein Wörterbuch, in dem der emotionale Wert jedes Wortes eingetragen ist. In einem Stimmungswörterbuch ist zum Beispiel eingetragen, dass freundlich ein positives Wort, aber gemein ein negatives Wort ist.\n\nDenkpause\nWie könnten Sie ein solches Wörterbuch erstellen?\n\nDie Universität Leipzig hat ein Stimmungswörterbuch für das Deutsche namens SentimentWortschatz oder SentiWS erstellt (Remus, Quasthoff, und Heyer 2010). Ich habe das Wörterbuch für Sie vorbereitet. Laden Sie das Wörterbuch in R mit folgenden Befehlen.\n\nsentiWS<-read.table(\"./data/sentiWS.txt\", sep = \"\\t\", header = TRUE)\nsentiWS<-as_tibble(sentiWS)\nsentiWS\n\nIm Wörterbuch haben alle Einträge einen Wert zwischen -1 und 1. Ein positiver Wert zeigt eine positive Stimmung an, ein negativer Wert eine negative Stimmung. Ergänzen Sie das Wörterbuch um einen Faktor POLARITY, der anzeigt, ob ein Wort positiv oder negativ ist.\n\nsentiWS<-sentiWS %>% \n  mutate(POLARITY = ifelse(VALUE < 0, \"negative\", \"positive\"))\nsentiWS\n\nSuchen Sie jetzt die Einträge für freundlich und gemein im Wörterbuch.\n\nDenkpause\nWas werden die Einträge für freundlich und gemein zeigen?\n\nNutzen Sie den Befehl filter().\n\nsentiWS %>%\n  filter(WORD == \"freundlich\")\nsentiWS %>%\n  filter(WORD == \"gemein\")\n\nGeben Sie jetzt jedem Wort in Ihrem Märchen mit der Funktion inner_join() einen Stimmungswert. (Notiz: Vermutlich ist nicht jedes Wort in Ihrem Märchen im Wörterbuch. Mit inner_join() werden nur die Wörter bearbeitet, die sowohl im Märchen als auch im Wörterbuch enthalten sind.)\n\n# Tokenisieren\ntokens_df<-text_df %>%\n  unnest_tokens(WORD, TEXT, to_lower = FALSE)\n\n# Stoppwörter\nstopwords_df<-tibble(read.csv(\"./data/stopwords.csv\"))\ntokens_df<-tokens_df %>%\n  anti_join(stopwords_df, by = \"WORD\")\n\n# Stimmungswerte\nsenti_df<-tokens_df %>%\n  inner_join(sentiWS, by = \"WORD\")\nsenti_df\n\nWelche Wörter tragen besonders stark zur Stimmung in Ihrem Märchen bei? Der folgende Code erzeugt eine Balkengrafik zur Veranschaulichung der Häufigkeit verschiedener Wörter (Types) und ihrer Stimmung.\n\nlibrary(ggplot2)\n\nsenti_df %>%\n  count(TYPE, POLARITY, sort = TRUE) %>%\n  group_by(POLARITY) %>%\n  mutate(TYPE = reorder(TYPE, n)) %>%\n  slice_head(n = 30) %>%\n  ggplot(aes(n, TYPE, fill = POLARITY)) +\n  geom_col(show.legend = FALSE) + \n  facet_wrap(~POLARITY, scales = \"free\") + \n  labs(y=NULL, x=NULL)\n\n\nlibrary(ggplot2)\n\nsenti_df %>%\n  count(TYPE, POLARITY, sort = TRUE) %>%\n  group_by(POLARITY) %>%\n  mutate(TYPE = reorder(TYPE, n)) %>%\n  slice_head(n = 30) %>%\n  ggplot(aes(n, TYPE, fill = POLARITY)) +\n  geom_col(show.legend = FALSE) + \n  facet_wrap(~POLARITY, scales = \"free\") + \n  labs(y=NULL, x=NULL)\n\nAuch eine schöne Art, Häufigkeiten zu veranschaulichen, sind Wortwolken.\n\nsenti_df %>%\n  count(TYPE, POLARITY, sort = TRUE) %>%\n  acast(TYPE ~ POLARITY, value.var = \"n\", fill = 0) %>%\n  comparison.cloud(colors = c(\"#B4464B\", \"#4682B4\"),\n                   max.words = 100, title.size = 1)\n\nVergleichen Sie Ihre Märchen miteinander. Welche Gemeinsamkeiten, welche Unterschiede finden Sie? Wie gut passt das Ergebnis mit Ihrem subjektiven Leseeindruck zusammen?\n\nDenkpause\nWelches grundlegende Problem hat dieser Ansatz zur Stimmungsanalyse?\n\n\nTipp\n\nWelche Stimmung drückt folgender Satz aus:\nIch habe keinen guten Tag.\n\n\n\n\nStimmung vergleichen\nIm Folgenden analysieren und interpretieren Sie die Stimmung in deutschen, chinesischen und arabischen Volksmärchen.\n\nDenkpause\nBevor Sie beginnen: Erwarten Sie Ihrem Gefühl nach Unterschiede? Wenn ja, welche?\n\nWiederholen Sie die Analyse für die drei Märchen-Korpora.\nLesen Sie als Erstes die Korpora ein. Zur Erinnerung:\n\nsrc<-list.files(\"./data/corpus-wilhelm/\")\ndf<-data.frame(matrix(nrow = length(src), ncol = 2))\ncolnames(df)<-c(\"TEXT\", \"DATEI\")\nfor(i in 1:length(src)){\n  df[i,1]<-readLines(paste(\"./data/corpus-wilhelm/\", src[i], sep = \"\"))\n  df[i,2]<-src[i]\n}\nwilhelm<-as_tibble(df)\n\nsrc<-list.files(\"./data/corpus-grimm/\")\ndf<-data.frame(matrix(nrow = length(src), ncol = 2))\ncolnames(df)<-c(\"TEXT\", \"DATEI\")\nfor(i in 1:length(src)){\n  df[i,1]<-readLines(paste(\"./data/corpus-grimm/\", src[i], sep = \"\"))\n  df[i,2]<-src[i]\n}\ngrimm<-as_tibble(df)\n\nsrc<-list.files(\"./data/corpus-weil/\")\ndf<-data.frame(matrix(nrow = length(src), ncol = 2))\ncolnames(df)<-c(\"TEXT\", \"DATEI\")\nfor(i in 1:length(src)){\n  df[i,1]<-readLines(paste(\"./data/corpus-weil/\", src[i], sep = \"\"))\n  df[i,2]<-src[i]\n}\nweil<-as_tibble(df)\n\nrm(df, i, src)\n\n\n\n\n\n\nLiteratur\n\nRemus, Robert, Uwe Quasthoff, und Gerhard Heyer. 2010. „SentiWS - A Publicly Available German-language Resource for Sentiment Analysis“. In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10). Valletta: European Language Resources Association (ELRA). http://www.lrec-conf.org/proceedings/lrec2010/pdf/490_Paper.pdf."
  },
  {
    "objectID": "cosine-similarity.html",
    "href": "cosine-similarity.html",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "",
    "text": "Das letzte Mal haben Sie versucht, die (inhaltliche) Ähnlichkeit Ihrer Märchen intuitiv und von Hand zu bestimmen. Die cosine similarity ist eine Methode, um die inhaltliche Ähnlichkeit von Texten automatisch zu bestimmen.\nIm Folgenden werden Sie (1) eine term-document-Matrix erzeugen, (2) die Ähnlichkeit zwischen Ihren Märchen errechnen und (3) die Ergebnisse in einer heatmap visualisieren. Anschließend versuchen Sie, (4) ähnliche deutsche, chinesische und arabische Märchen zu finden.\n\nPakete installieren\nBevor Sie beginnen, laden Sie folgende Pakete.\n\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(tm)\nlibrary(tools)\nlibrary(reshape2)\nlibrary(ggplot2)\nlibrary(text2vec)\n\nLaden Sie jetzt ein Sample aus dem Märchenkorpus.\n\nsrc<-list.files(\"./data/sample/\")\ndf<-data.frame(matrix(nrow = length(src), ncol = 2))\ncolnames(df)<-c(\"TEXT\", \"TITLE\")\nfor(i in 1:length(src)){\n  df[i,1]<-readLines(paste(\"./data/sample/\", src[i], sep = \"\"))\n  df[i,2]<-sub(\".txt\", \"\", src[i], fixed = TRUE)\n}\nsample<-as_tibble(df)\nsample\n\n\n\nterm-document-Matrix\nIm ersten Schritt erzeugen Sie eine document-term-Matrix. In einer document-term-Matrix werden die documents (Texte, Märchen) in den Zeilen, die terms (Wörter) in den Spalten abgebildet. In den Zellen wird abgebildet, wie oft ein Wort in einem Text vorkommt.\nErrechnen Sie zuerst die Worthäufigkeiten für jedes Märchen einzeln, d.h. zählen Sie die Wörter in jedem Märchen.\n\n\nHilfe\n\n\nstopwords_df<-tibble(read.csv(\"./data/stopwords.csv\"))\n\nsample_freq<-sample %>%\n  unnest_tokens(WORD, TEXT, to_lower = FALSE) %>%\n  anti_join(stopwords_df, by = \"WORD\") %>%\n  dplyr::count(WORD, TITLE, sort = TRUE)\nsample_freq\n\n\nDie folgende Funktion cast_dtm() macht aus Ihrem tibble eine document-term-Matrix. Schauen Sie sich die Matrix mit inspect() an und überprüfen Sie einige Werte von Hand.\n\nsample_dtm<-sample_freq %>%\n  cast_dtm(TITLE, WORD, n) \n\ntm::inspect(sample_dtm)\n\n\nDenkpause\nSie haben jetzt eine Märchen-Wörter-Matrix, die anzeigt, wie oft jedes Wort in jedem Märchen vorkommt. Sie möchten aber die inhaltliche Ähnlichkeit der Märchen bestimmen. Was könnten Sie tun?\n\n\n\nÄhnlichkeit errechnen\nDie Ähnlichkeit zwischen den Märchen bestimmen Sie als Cosinus-Ähnlichkeit (cosine similarity). Die cosine similarity ist unabhängig von der Textlänge.\nDie Ähnlichkeit zwischen zwei Texten wird dabei als Winkel zwischen zwei Vektoren in einem mehrdimensionalen Raum ausgedrückt. Jedes Wort bildet eine Dimension. Jedes Märchen hat eine Position auf dieser Dimension, abhängig davon, wie häufig dieses Wort in diesem Text vorkommt. Jedes Märchen ist dann als Vektor im Raum abbildbar. Der Winkel zwischen den Vektoren (Märchen) zeigt ihre Ähnlichkeit (ihre ähnliche Orientierung im Wörter-Raum) an.\nVereinfachtes Beispiel mit zwei Wörtern (Dimensionen) und drei Märchen (Vektoren).\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n \n  \n    Titel \n    König \n    schlafen \n  \n \n\n  \n    Schneewittchen \n    9 \n    8 \n  \n  \n    Aschenputtel \n    7 \n    9 \n  \n  \n    Brüderchen und Schwesterchen \n    8 \n    1 \n  \n\n\n\n\n\n\n\n\n\nDie cosine similarity wird automatisch ermittelt mit der Funktion sim2(). Der Cosinus varriert zwischen 0 und 1: 0 bedeutet keine Ähnlichkeit, 1 bedeutet größtmögliche Ähnlichkeit (Identität).\n\nsample_cos<-sample_dtm %>%\n  as.matrix() %>%\n  sim2(method = \"cosine\")\nsample_cos\n\n\n\nHeatmap\nDie Ergebnisse sind in dieser Form nur schwierig interpretierbar. Veranschaulichen Sie die Ergebnisse in einer heatmap.\n\nsample_cos<-melt(sample_cos)\ncolnames(sample_cos)<-c(\"TITLE1\", \"TITLE2\", \"value\")\n\nggplot(data = sample_cos, aes(x=TITLE1, y=TITLE2 , fill=value, text=value)) + \n  geom_tile(color = \"white\") + \n  geom_text(aes(TITLE2, TITLE1, label = round(value,1)), color = \"white\", size = 4) +\n  theme_minimal() + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +\n  coord_fixed() + \n  labs(x =\"\", y=\"\", fill = \"Cosinus\")\n\nVergleichen Sie die Ergebnisse der Ähnlichkeitsanalyse mit Ihren intuitiven Urteilen. Stimmen sie überein? Finden Sie die errechneten Werte brauchbar?\n\n\nMärchen vergleichen\nZum Ende versuchen Sie, die Ähnlichkeit zwischen deutschen und chinesischen Volksmärchen zu ermitteln. Finden Sie die zwei ähnlichsten Märchen.\nLaden Sie zuerst beide Märchen-Korpora mit folgendem Code.\n\nsrc<-list.files(\"./data/corpus-grimm/\")\ndf<-data.frame(matrix(nrow = length(src), ncol = 3))\ncolnames(df)<-c(\"TEXT\", \"TITLE\", \"SOURCE\")\nfor(i in 1:length(src)){\n  df[i,1]<-readLines(paste(\"./data/corpus-grimm/\", src[i], sep = \"\"))\n  df[i,2]<-sub(\".txt\", \"\", src[i], fixed = TRUE)\n  df[i,3]<-\"Grimm\"\n}\ngrimm<-as_tibble(df)\n\nsrc<-list.files(\"./data/corpus-wilhelm/\")\ndf<-data.frame(matrix(nrow = length(src), ncol = 3))\ncolnames(df)<-c(\"TEXT\", \"TITLE\", \"SOURCE\")\nfor(i in 1:length(src)){\n  df[i,1]<-readLines(paste(\"./data/corpus-wilhelm/\", src[i], sep = \"\"))\n  df[i,2]<-sub(\".txt\", \"\", src[i], fixed = TRUE)\n  df[i,3]<-\"Wilhelm\"\n}\nwilhelm<-as_tibble(df)\n\ncorpus<-tibble(rbind(grimm, wilhelm))\n\nWiederholen Sie jetzt die Schritte (1) (document-term-Matrix errechnen) und (2) (Cosinus-Ähnlichkeit der Märchen errechnen). Das Ergebnis ist eine Matrix mit Ähnlichkeitswerten für alle Märchen-Paare. Wenn Sie Hilfe brauchen, klicken Sie auf Hilfe.\n\n\nHilfe\n\n\nstopwords_df<-tibble(read.csv(\"./data/stopwords.csv\"))\n\ncorpus_words<-corpus %>%\n  unnest_tokens(WORD, TEXT, to_lower = FALSE) %>%\n  anti_join(stopwords_df, by = \"WORD\") %>%\n  dplyr::count(WORD, TITLE, SOURCE, sort = TRUE)\n\ncorpus_dtm<-corpus_words %>%\n  cast_dtm(TITLE, WORD, n) \n\ncorpus_cos<-corpus_dtm %>%\n  as.matrix() %>%\n  sim2(method = \"cosine\")\n\n\n\nSie haben eine Matrix mit den Ähnlichkeitswerten für alle Märchen-Paare erzeugt. Die Herkunft der Märchen (deutsch oder chinesisch oder arabisch) ist dabei verloren gegangen. Sie müssen sie wieder eintragen, mit folgendem Code.\n\ncorpus_cos<-corpus_cos %>%\n  melt() %>%\n  rename(\"TITLE1\" = 1, \"TITLE2\" = 2) %>%\n  left_join(corpus[,2:3], by = c(\"TITLE1\" = \"TITLE\")) %>%\n  left_join(corpus[,2:3], by = c(\"TITLE2\" = \"TITLE\"))\n\nJetzt wählen Sie alle deutsch-chinesischen-arabischen Märchen-Paare aus (filter()), ordnen sie die Ergebnisse nach Ähnlichkeit (arrange()) und zeigen Sie den ersten Eintrag an (slice_head()).\n\nsim<-corpus_cos %>%\n  filter(SOURCE.x != SOURCE.y) %>%\n  arrange(-value) %>%\n  slice_head(n = 1)\nsim\n\ndiff<-corpus_cos %>%\n  filter(SOURCE.x != SOURCE.y) %>%\n  arrange(-value) %>%\n  slice_tail(n = 1)\ndiff\n\nDie Analyse hat ergeben, dass dieses deutsche und dieses chinesische Märchen sich inhaltlich am ähnlichsten bzw. unähnlichsten sind. Lesen und vergleichen Sie die Märchen, um dieses Ergebnis zu überprüfen."
  },
  {
    "objectID": "topic-modeling.html",
    "href": "topic-modeling.html",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "",
    "text": "Das letzte Mal haben Sie versucht, Ihre Märchen in Gruppen einzuteilen und Themen zu bestimmen. Ein Computer benutzt für diese Aufgaben clustering und topic modeling. Das ist schwierig und mathematisch kompliziert, aber intuitiv verständlich.\nIm Folgenden werden Sie (1) eine Distanz-Matrix erzeugen, (2) Ihre Märchen in Cluster gruppieren und die Ergebnisse visualisieren und (3) Themen in Ihren Märchen bestimmen. Für Details siehe Levshina (2015) und Silge und Robinson (2017). Anschließend (4) wiederholen Sie die Analyse mit allen Märchen und versuchen, typische Themen für bestimmte Kulturkreise (deutsch, chinesisch, arabisch) zu ermitteln.\n\nPakete installieren\nBevor Sie beginnen, laden Sie folgende Pakete und laden Sie Ihr Sample in R.\n\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(tools)\nlibrary(topicmodels)\nlibrary(tidyr)\nlibrary(ape)\nlibrary(cluster)\n\n\nsrc<-list.files(\"./data/sample/\")\ndf<-data.frame(matrix(nrow = length(src), ncol = 2))\ncolnames(df)<-c(\"TEXT\", \"TITLE\")\nfor(i in 1:length(src)){\n  df[i,1]<-readLines(paste(\"./data/sample/\", src[i], sep = \"\"))\n  df[i,2]<-sub(\".txt\", \"\", src[i], fixed = TRUE)\n}\nsample<-df\n\n\n\nDistanz-Matrix erzeugen\nErstellen Sie zunächst eine document-term-Matrix für Ihre Märchen. Zur Erinnerung: Eine document-term-Matrix zeigt an, wie häufig jedes Wort in jedem Märchen vorkommt.\n\n\nHilfe\n\n\nstopwords_df<-tibble(read.csv(\"./data/stopwords.csv\"))\n\ndtm<-sample %>%\n  unnest_tokens(WORD, TEXT, to_lower = FALSE) %>%\n  anti_join(stopwords_df, by = \"WORD\") %>%\n  dplyr::count(WORD, TITLE, sort = TRUE) %>% \n  cast_dtm(TITLE, WORD, n) %>%\n  as.matrix()\ndtm[1:4, 1:5]\n\n\nWie Sie schon gelernt haben, zeigt die document-term-Matrix die inhaltliche Ähnlichkeit zwischen den Märchen an. Dieses Mal brauchen Sie aber die Unterschiede. Sie können Ihre Ähnlichkeitsmatrix mit der Funktion dist() in eine Unterschiedlichkeitsmatrix (distance matrix) umwandeln.\n\ndistanceMatrix<-dist(dtm)\ndistanceMatrix\n\n\n\nClustern und Cluster visualisieren\nJetzt bilden Sie Cluster, d.h. Sie gruppieren ähnliche Märchen zusammen. Das hier verwendete Verfahren heißt hierarchical agglomerative clustering. Es funktioniert im Prinzip so: Alle Märchen werden als Äste an einem Baum abgebildet. Der Baum wächst aber nicht von innen nach außen, sondern von außen nach innen. Der Computer vergleicht alle Märchen miteinander und gruppiert dann die ähnlichsten zusammen. Sie bilden die äußeren Äste. Dann vergleicht der Computer die Äste und gruppiert die ähnlichen wieder zusammen. So bilden sich dickere Äste. Und so weiter, bis zum Stamm.\n\nDie Funktion hclust() (hierarchical cluster) gruppiert die Märchen in einem Baum. Anschließend können Sie die Ergebnisse mit plot und as.phylo() anzeigen. So ein Baum heißt Dendrogramm.\n\ntree<-hclust(distanceMatrix, method = \"ward.D2\")\nplot(as.phylo(tree))\n\nAlternativ können Sie den Baum auch als Fächer oder als Baum ohne Wurzeln darstellen.\n\nplot(as.phylo(tree), type = \"fan\")\nplot(as.phylo(tree), type = \"unrooted\", cex = 0.6, no.margin = TRUE)\n\n\nDenkpause\nWas genau zeigt das Dendrogramm an? Denken Sie nach und formulieren Sie in eigenen Worten. Welche Märchen bilden im Dendrogramm eine Gruppe? Wie viele Gruppen zeigen sich?\n\nWie viele Gruppen sind sinnvoll? Eine Gruppe, zwei Gruppen, drei oder mehr? Sie sollen die Märchen so gruppieren, dass die Ähnlichkeit innerhalb der Gruppe möglichst groß und zwischen den Gruppen möglichst klein ist. Die Funktion silhouette() ermittelt, wie gut die Gruppen voneinander unterscheidbar sind. So können Sie die optimale Anzahl von Gruppen bestimmen.\n\nk<-2 # zwei Cluster\nk<-3 # drei Cluster\nk<-4 # vier Cluster\n\nclusterN<-cutree(tree, k)\n\ncolors<-rainbow(k)\nplot(as.phylo(tree), type = \"fan\", tip.color = colors[clusterN], label.offset = 5, cex = 0.7)\n\nsummary(silhouette(clusterN, distanceMatrix))$avg.width\n\nnClusters<-2:9\nasw<-sapply(nClusters, function(x) summary(silhouette(cutree(tree, k = x), distanceMatrix))[\"avg.width\"])\nplot(nClusters, asw, type = \"b\")\n\n\n\nThemen bestimmen\nUm die Themen in Ihren Märchen zu bestimmen, nutzen Sie einen Algorithmus namens Latent Dirichlet allocation (LDA). Die mathematischen Grundlagen müssen Sie wieder ignorieren. Der Algorithmus basiert auf zwei Annahmen:\n\nJedes Märchen ist eine Mischung aus verschiedenen Themen.\nJedes Thema ist eine Mischung aus verschiedenen Wörtern.\n\nLDA ist eine mathematische Methode, die beides zur selben Zeit ermittelt: eine Mischung aus Themen für jedes Dokument und eine Mischung aus Wörtern für jedes Thema.\nDie Funktion LDA() benötigt dafür eine document-term-Matrix. Außerdem müssen Sie bei dieser Art von Statistik vorgeben, mit wie vielen Gruppen der Algorithmus arbeiten soll.\n\nDenkpause\nVersuchen Sie einzuschätzen, wie viele verschiedene Themen in Ihren Märchen vorkommen.\n\nWenn Sie eine mögliche Anzahl von Themen eingeschätzt haben, führen Sie die Funktion aus. Der Parameter k gibt die Anzahl der Themen an.\n\nlda<-LDA(dtm, k = 5)\nlda\n\nJedes Thema ist eine Mischung aus Wörtern, erinnern Sie sich? Das ermittelte Modell enthält einen Wert beta, der angibt, wie wahrscheinlich ein bestimmtes Wort einem bestimmten Thema angehört. Der folgende Code ermittelt die zehn wahrscheinlichsten Wörter für jedes Thema. Versuchen Sie, jedem Thema einen Namen zu geben.\n\nword_topic<-tidy(lda, matrix = \"beta\")\nword_topic %>%\n  group_by(topic) %>%\n  top_n(10, beta) %>%\n  ungroup() %>%\n  arrange(topic, -beta) %>%\n  mutate(term = reorder_within(term, beta, topic)) %>%\n  ggplot(aes(beta, term, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ topic, scales = \"free\") +\n  scale_y_reordered()\n\nJetzt möchten Sie noch ermitteln, wie viel von jedem Thema jedes Märchen enthält. Das Modell enthält einen Wert gamma, der angibt, wie wahrscheinlich ein bestimmtes Thema in einem bestimmten Märchen ist.\n\nDenkpause\nBevor Sie weitermachen, versuchen Sie einzuschätzen, wie wahrscheinlich jedes Thema in jedem Ihrer Märchen ist.\n\nDer folgende Code ermittelt die Märchen-Thema-Wahrscheinlichkeit.\n\ndocument_topic<-tidy(lda, matrix = \"gamma\")\n\ndocument_topic %>%\n  mutate(document = reorder(document, gamma * topic)) %>%\n  ggplot(aes(factor(topic), gamma)) +\n  geom_boxplot() +\n  facet_wrap(~ document) +\n  labs(x = \"topic\", y = expression(gamma))\n\nVergleichen Sie das Ergebnis mit Ihrer Einschätzung.\n\n\nMärchen vergleichen\nVersuchen Sie jetzt, typische Themen für bestimmte Kulturkreise (deutsch, chinesisch, arabisch) zu ermitteln. Tipp: Nutzen Sie nicht das ganze Korpus, sondern eine Stichprobe! Das ganze Korpus ist zu groß für unsere kleinen Computer.\n\n\nHilfe\n\n\nsrc<-list.files(\"./data/corpus-grimm/\")\ndf<-data.frame(matrix(nrow = length(src), ncol = 3))\ncolnames(df)<-c(\"TEXT\", \"TITLE\", \"SOURCE\")\nfor(i in 1:length(src)){\n  df[i,1]<-readLines(paste(\"./data/corpus-grimm/\", src[i], sep = \"\"))\n  df[i,2]<-sub(\".txt\", \"\", src[i], fixed = TRUE)\n  df[i,3]<-\"Deutsch\"\n}\ngrimm<-as_tibble(df)\n\nsrc<-list.files(\"./data/corpus-wilhelm/\")\ndf<-data.frame(matrix(nrow = length(src), ncol = 3))\ncolnames(df)<-c(\"TEXT\", \"TITLE\", \"SOURCE\")\nfor(i in 1:length(src)){\n  df[i,1]<-readLines(paste(\"./data/corpus-wilhelm/\", src[i], sep = \"\"))\n  df[i,2]<-sub(\".txt\", \"\", src[i], fixed = TRUE)\n  df[i,3]<-\"Chinesisch\"\n}\nwilhelm<-as_tibble(df)\n\nsrc<-list.files(\"./data/corpus-weil/\")\ndf<-data.frame(matrix(nrow = length(src), ncol = 3))\ncolnames(df)<-c(\"TEXT\", \"TITLE\", \"SOURCE\")\nfor(i in 1:length(src)){\n  df[i,1]<-readLines(paste(\"./data/corpus-weil/\", src[i], sep = \"\"))\n  df[i,2]<-sub(\".txt\", \"\", src[i], fixed = TRUE)\n  df[i,3]<-\"Arabisch\"\n}\nweil<-as_tibble(df)\n\ncorpus<-tibble(rbind(grimm, wilhelm, weil))\n\n# Zufallsstichprobe \ncorpus<-corpus %>%\n  group_by(SOURCE) %>%\n  sample_n(size = 50) %>%\n  ungroup()\n\n# Stopwörter entfernen\nstopwords_df<-tibble(read.csv(\"./data/stopwords.csv\"))\n\n# Distanz-Matrix erzeugen\ndtm<-corpus %>%\n  unnest_tokens(WORD, TEXT, to_lower = FALSE) %>%\n  anti_join(stopwords_df, by = \"WORD\") %>%\n  dplyr::count(WORD, TITLE, sort = TRUE) %>% \n  cast_dtm(TITLE, WORD, n) %>%\n  as.matrix()\n\n\n# Latent Dirichlet allocation ermittelt Themen je Märchen und Wörter je Thema\nlda<-LDA(dtm, k = 10)\nlda\n\n\n# Wahrscheinlichkeit Thema/Märchen\ndocument_topic<-tidy(lda, matrix = \"gamma\")\n\n# Quelle Märchen hinzufügen\ndocument_topic<-document_topic %>%\n  left_join(corpus[,c(\"TITLE\", \"SOURCE\")], by = c(\"document\" = \"TITLE\"))\n\n# Wahrscheinlichkeit Themen nach Quelle\ndocument_topic %>%\n  ggplot(aes(factor(topic), gamma)) +\n  geom_boxplot(aes(y=gamma, fill=SOURCE)) +\n  facet_wrap(~ SOURCE) +\n  labs(x = \"topic\", y = expression(gamma)) + \n  theme_minimal() + \n  labs(y = \"gamma\")\n\n# Wahrscheinlichkeit Wörter/Thema\nword_topic<-tidy(lda, matrix = \"beta\")\nword_topic %>%\n  group_by(topic) %>%\n  top_n(10, beta) %>%\n  ungroup() %>%\n  arrange(topic, -beta) %>%\n  mutate(term = reorder_within(term, beta, topic)) %>%\n  ggplot(aes(beta, term, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ topic, scales = \"free\") +\n  scale_y_reordered()\n\n\n\n\n\n\n\nLiteratur\n\nLevshina, Natalia. 2015. How to Do Linguistics with R: Data Exploration and Statistical Analysis. Amsterdam: John Benjamins. https://doi.org/10.1075/z.195.\n\n\nSilge, Julia, und David Robinson. 2017. Text Mining with R: A Tidy Approach. Sebastopol, CA: O’Reilly. https://www.tidytextmining.com/."
  },
  {
    "objectID": "morphological-analysis.html",
    "href": "morphological-analysis.html",
    "title": "MäRchen: Text Mining mit den sieben Zwergen",
    "section": "",
    "text": "Der sowjetische Sprachwissenschaftler Vladimir Propp (1895-1970) hat 1928 - genau wie Sie gerade - russische Märchen miteinander verglichen und nach einem Muster gesucht. Er hat eine Morphologie des Märchens (Propp 1972) erstellt.\nDas Wort Morphologie bedeutet, Propp beschreibt die Funktionen der verschiedenen Teile in einem Märchen. Er ist wie ein Biologe, der die Körperteile einer Ameise nach ihren Funktionen beschreibt. Ein Vergleich vieler Ameisen zeigt, dass alle Ameisen Augen zum Sehen, Fühler zum Riechen, Beine zum Laufen usw. haben.\n\nEin Vergleich vieler Märchen zeigt, dass alle Märchen Teile mit folgenden Funktionen haben. Nach Propp kommen nicht alle Funktionen in allen Märchen vor, aber sie erscheinen immer in dieser Reihenfolge.\n\n\nEntfernung\nVerbot\nVerstoß\nNachforschung\nDenunziation\nHinterhalt\nMitwisserschaft\nSchädigung (oder Versäumnis)\nVermittlung\nZustimmung des Helden\nAufbruch des Helden\nPrüfung des Helden durch den Spender\nReaktion des Helden\nLieferung des Zauberinstruments\nOrtswechsel des Helden\nKampf zwischen dem Helden und seinem Gegenspieler\nDer gezeichnete Held\nSieg über den Gegenspieler\nAbwendung des Unglücks oder Versagen wie am Beginn\nRückkehr des Helden\nSeine Verfolgung\nDer Held rettet sich\nDer Held kehrt unerkannt nach Hause zurück\nAnsprüche des falschen Helden\nDem Helden wird eine schwere Aufgabe auferlegt\nAusführung der Aufgabe\nAnerkennung des Helden\nEntlarvung des falschen Helden oder des Gegenspielers\nVerwandlung des Helden\nBestrafung des Gegenspielers\nHochzeit des Helden\n\n\n\n\n\n\nLiteratur\n\nPropp, Vladimir. 1972. Morphologie des Märchens. München: Hanser."
  }
]